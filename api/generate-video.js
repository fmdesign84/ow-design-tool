/**
 * Vercel Serverless Function - Video Generation (Veo 3.1)
 *
 * Image-to-Video generation using Google Veo 3.1
 * - Long-running operation with polling
 * - Supports audio generation
 * - 4/6/8 second durations
 * - Error logging to Supabase
 * - Friendly error messages via Gemini Flash
 */

const { GoogleAuth } = require('google-auth-library');
const { createClient } = require('@supabase/supabase-js');

/**
 * ì—ëŸ¬ ë¡œê¹… í•¨ìˆ˜ - Supabaseì— ì—ëŸ¬ ê¸°ë¡
 */
async function logError(errorType, errorMessage, requestData, responseData = null) {
    try {
        const supabaseUrl = process.env.SUPABASE_URL;
        const supabaseKey = process.env.SUPABASE_ANON_KEY;

        if (!supabaseUrl || !supabaseKey) {
            console.log('[ErrorLog] Supabase not configured, skipping log');
            return;
        }

        const supabase = createClient(supabaseUrl, supabaseKey);

        const { error } = await supabase.from('error_logs').insert({
            service: 'generate-video',
            error_type: errorType,
            error_message: errorMessage,
            request_data: requestData,
            response_data: responseData,
            resolved: false
        });

        if (error) {
            console.error('[ErrorLog] Failed to log error:', error);
        } else {
            console.log('[ErrorLog] Error logged successfully:', errorType);
        }
    } catch (e) {
        console.error('[ErrorLog] Exception:', e.message);
    }
}

/**
 * Gemini Flashë¡œ ì¹œê·¼í•œ ì—ëŸ¬ ë©”ì‹œì§€ ìƒì„±
 */
async function generateFriendlyMessage(context, accessToken, projectId) {
    const { errorType, errorMessage, prompt } = context;

    const location = 'us-central1';
    const systemPrompt = `ë‹¹ì‹ ì€ AI ì˜ìƒ ìƒì„± ì„œë¹„ìŠ¤ì˜ ì¹œì ˆí•œ ì•ˆë‚´ì›ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì—ê²Œ ìƒí™©ì„ ë¶€ë“œëŸ½ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, 1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.

ìƒí™©:
- ì—ëŸ¬ ìœ í˜•: ${errorType}
- ì—ëŸ¬ ë©”ì‹œì§€: ${errorMessage}
- ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸: "${prompt?.substring(0, 100) || '(ì—†ìŒ)'}"

ë‹¤ìŒ ê°€ì´ë“œë¼ì¸ì„ ë”°ë¥´ì„¸ìš”:
1. ì•ˆì „ ì •ì±… ìœ„ë°˜ (usage guidelines, violate, blocked) â†’ message: "ìš”ì²­í•˜ì‹  ì˜ìƒì´ ì•ˆì „ ì •ì±…ì— ë§ì§€ ì•Šì•„ ìƒì„±ì´ ì–´ë ¤ì›Œìš”. ì¡°ê¸ˆ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì‹œë„í•´ë³´ì‹œê² ì–´ìš”? ğŸ¬", detail: ì™œ ì´ëŸ° ì—ëŸ¬ê°€ ë‚¬ëŠ”ì§€ êµ¬ì²´ì  ì„¤ëª…ê³¼ í•´ê²° ì˜ˆì‹œ (ì˜ˆ: ì‹¤ì¡´ ì¸ë¬¼+ì €ì‘ê¶Œ ìºë¦­í„° ì¡°í•©ì€ ê±°ë¶€ë  ìˆ˜ ìˆìœ¼ë‹ˆ ì¼ë°˜ì  í‘œí˜„ ì‚¬ìš© ê¶Œì¥)
2. íƒ€ì„ì•„ì›ƒ â†’ message: "ì˜ìƒ ìƒì„±ì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê³  ìˆì–´ìš”. ì‚¬ìš©ìê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! â³", detail: null
3. ì¼ì‹œì  ì˜¤ë¥˜ â†’ message: "ì ì‹œ ì„œë²„ê°€ ë°”ë¹´ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! ğŸ”„", detail: null
4. í•„í„°ë§ (RAI, filtered) â†’ message: "ì½˜í…ì¸  ì •ì±…ìœ¼ë¡œ ì¸í•´ ì˜ìƒì´ í•„í„°ë§ë˜ì—ˆì–´ìš”. ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¡œ ì‹œë„í•´ë³´ì„¸ìš” âœ¨", detail: ì›ì¸ ì„¤ëª…
5. ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ â†’ message: "ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš” ğŸ™", detail: null

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ: {"message": "ì¹œí™”ì  ë©”ì‹œì§€", "suggestion": "ì¶”ê°€ ì œì•ˆ(ì„ íƒ)", "detail": "ì›ì¸ ì„¤ëª…(ì•ˆì „ ì •ì±… ìœ„ë°˜ì‹œë§Œ)"}`;

    try {
        const geminiUrl = `https://${location}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${location}/publishers/google/models/gemini-3-flash-preview:generateContent`;

        const response = await fetch(geminiUrl, {
            method: 'POST',
            headers: {
                Authorization: `Bearer ${accessToken}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                contents: [{ role: 'user', parts: [{ text: systemPrompt }] }],
                generationConfig: {
                    temperature: 0.7,
                    maxOutputTokens: 200,
                    responseMimeType: 'application/json'
                }
            })
        });

        if (!response.ok) {
            console.log('[Flash Communicator] API failed, using default message');
            return getDefaultMessage(context);
        }

        const data = await response.json();
        const result = data.candidates?.[0]?.content?.parts?.[0]?.text?.trim();

        if (result) {
            const jsonMatch = result.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                const parsed = JSON.parse(jsonMatch[0]);
                console.log('[Flash Communicator] Generated:', parsed.message);
                return parsed;
            }
        }
    } catch (e) {
        console.log('[Flash Communicator] Error:', e.message);
    }

    return getDefaultMessage(context);
}

/**
 * ê¸°ë³¸ ë©”ì‹œì§€ (Flash ì‹¤íŒ¨ ì‹œ)
 */
function getDefaultMessage(context) {
    const { errorMessage } = context;
    const msg = errorMessage?.toLowerCase() || '';
    const msgKr = errorMessage || ''; // í•œêµ­ì–´ ì›ë³¸ ìœ ì§€

    if (msg.includes('usage guidelines') || msg.includes('violate') || msg.includes('blocked')) {
        return {
            message: "ìš”ì²­í•˜ì‹  ì˜ìƒì´ ì•ˆì „ ì •ì±…ì— ë§ì§€ ì•Šì•„ ìƒì„±ì´ ì–´ë ¤ì›Œìš”. ì¡°ê¸ˆ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì‹œë„í•´ë³´ì‹œê² ì–´ìš”? ğŸ¬",
            suggestion: "í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•´ë³´ì„¸ìš”",
            detail: "ğŸ’¡ ì‹¤ì¡´ ì¸ë¬¼(ìŠ¤í‹°ë¸Œ ì¡ìŠ¤, ì¼ë¡  ë¨¸ìŠ¤í¬ ë“±)ì´ë‚˜ ì €ì‘ê¶Œ ìºë¦­í„°(ì•„ì´ì–¸ë§¨, ìŠ¤íŒŒì´ë”ë§¨ ë“±)ëŠ” ê°œë³„ë¡œëŠ” ìƒì„±ë˜ì–´ë„, ì¡°í•©í•˜ë©´ ê±°ë¶€ë  ìˆ˜ ìˆì–´ìš”. 'ê²€ì€ í„°í‹€ë„¥ì˜ CEO', 'ë¹¨ê°„ ê¸ˆì† ìŠˆíŠ¸ íˆì–´ë¡œ' ì²˜ëŸ¼ ì¼ë°˜ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”."
        };
    }

    if (msg.includes('timeout')) {
        return {
            message: "ì˜ìƒ ìƒì„±ì— ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê³  ìˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”! â³",
            suggestion: null
        };
    }

    // ì˜ì–´ + í•œêµ­ì–´ í‚¤ì›Œë“œ ëª¨ë‘ ì²´í¬
    if (msg.includes('rai') || msg.includes('filter') ||
        msgKr.includes('í•„í„°ë§') || msgKr.includes('ì½˜í…ì¸  ì •ì±…')) {
        return {
            message: "ì½˜í…ì¸  ì •ì±…ìœ¼ë¡œ ì¸í•´ ì˜ìƒì´ í•„í„°ë§ë˜ì—ˆì–´ìš”. ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¡œ ì‹œë„í•´ë³´ì„¸ìš” âœ¨",
            suggestion: "ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”"
        };
    }

    return {
        message: "ì˜ˆìƒì¹˜ ëª»í•œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš” ğŸ™",
        suggestion: null
    };
}

/**
 * Gemini 3 Proë¡œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ Veo ìµœì í™” í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
 */
async function optimizePromptForVeo(userPrompt, mode, accessToken, projectId, imageData = null, endImageData = null) {
    const location = 'us-central1';

    // ëª¨ë“œë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    const systemPrompts = {
        'text-to-video': `You are a video generation prompt optimizer for Google Veo 3.1.
Transform the user's simple prompt into a cinematic, detailed video prompt.

Rules:
1. Add camera movements (dolly, pan, tracking shot, arc shot, etc.)
2. Add lighting descriptions (golden hour, dramatic lighting, soft ambient light)
3. Add motion details (smooth, dynamic, slow-motion, time-lapse)
4. Keep it concise but descriptive (2-3 sentences max)
5. Output ONLY the optimized prompt in English, nothing else
6. Do NOT add any explanation or notes

Example:
User: "ê³ ì–‘ì´ê°€ ë›°ì–´ë‹¤ë…€"
Output: "Smooth tracking shot following a playful cat running across a sunlit room. Camera follows with fluid motion, soft natural lighting creating warm shadows. Dynamic movement with subtle slow-motion moments."`,

        'image-to-video': `You are a video generation prompt optimizer for Google Veo 3.1 image-to-video.
Transform the user's prompt into an animation prompt that brings the image to life.

Rules:
1. Focus on natural motion that fits the image content
2. Add subtle camera movements (slow zoom, gentle pan, parallax)
3. Describe environmental motion (wind, particles, atmosphere)
4. Keep it concise (2-3 sentences max)
5. Output ONLY the optimized prompt in English, nothing else
6. Do NOT describe what's in the image - focus on HOW it moves

Example:
User: "ì˜ìƒìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜"
Output: "Gentle camera push-in with subtle parallax effect. Soft ambient motion with floating particles and gentle wind movement. Cinematic atmosphere with smooth, dreamy quality."`,

        'multi-image': `You are a video generation prompt optimizer for Google Veo 3.1 first-to-last frame interpolation.
This is CRITICAL: The user provided TWO images (first frame and last frame). You must describe the TRANSITION between them.

Rules:
1. DO NOT describe the images themselves
2. Describe the CAMERA MOVEMENT between the two frames (arc shot, dolly, pan, etc.)
3. Describe the TRANSFORMATION/TRANSITION (morph, smooth transition, dissolve)
4. Add timing cues (smooth, gradual, dynamic)
5. Keep it concise (2-3 sentences max)
6. Output ONLY the optimized transition prompt in English, nothing else

Example transitions:
- "Smooth 180-degree arc shot circling around the subject, maintaining focus while the background seamlessly transforms."
- "Gradual morph transition with gentle camera push-in, elements smoothly blending from first to last state."
- "Dynamic tracking shot following the transformation, camera fluid motion bridging both scenes naturally."`
    };

    const systemPrompt = systemPrompts[mode] || systemPrompts['text-to-video'];

    try {
        const geminiUrl = `https://${location}-aiplatform.googleapis.com/v1/projects/${projectId}/locations/${location}/publishers/google/models/gemini-3-flash-preview:generateContent`;

        // ìš”ì²­ êµ¬ì„±
        const parts = [{ text: `User prompt: "${userPrompt}"\n\nOptimize this for Veo 3.1 video generation:` }];

        // ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë¶„ì„ì— í¬í•¨ (image-to-video, multi-image ëª¨ë“œ)
        if (imageData && mode !== 'text-to-video') {
            parts.unshift({
                inlineData: {
                    mimeType: imageData.mime,
                    data: imageData.base64
                }
            });
        }

        // multi-image ëª¨ë“œì—ì„œ ë§ˆì§€ë§‰ í”„ë ˆì„ë„ í¬í•¨
        if (endImageData && mode === 'multi-image') {
            parts.push({
                inlineData: {
                    mimeType: endImageData.mime,
                    data: endImageData.base64
                }
            });
            parts.push({ text: "(Above are the first and last frame images. Describe the transition between them.)" });
        }

        const response = await fetch(geminiUrl, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${accessToken}`,
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                contents: [{ role: 'user', parts }],
                systemInstruction: { parts: [{ text: systemPrompt }] },
                generationConfig: {
                    temperature: 0.7,
                    maxOutputTokens: 256,
                }
            })
        });

        if (!response.ok) {
            console.error('[PromptOptimizer] Gemini API error:', response.status);
            return userPrompt; // ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
        }

        const data = await response.json();
        const optimizedPrompt = data.candidates?.[0]?.content?.parts?.[0]?.text?.trim();

        if (optimizedPrompt && optimizedPrompt.length > 10) {
            console.log('[PromptOptimizer] Original:', userPrompt);
            console.log('[PromptOptimizer] Optimized:', optimizedPrompt);
            return optimizedPrompt;
        }

        return userPrompt;
    } catch (error) {
        console.error('[PromptOptimizer] Error:', error.message);
        return userPrompt; // ì—ëŸ¬ì‹œ ì›ë³¸ ë°˜í™˜
    }
}

// Vercel Pro: ìµœëŒ€ 300ì´ˆ (5ë¶„)
module.exports.config = {
    maxDuration: 300,
};

module.exports = async (req, res) => {
    // CORS Handling
    res.setHeader('Access-Control-Allow-Credentials', true);
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'GET,OPTIONS,PATCH,DELETE,POST,PUT');
    res.setHeader(
        'Access-Control-Allow-Headers',
        'X-CSRF-Token, X-Requested-With, Accept, Accept-Version, Content-Length, Content-MD5, Content-Type, Date, X-Api-Version'
    );

    if (req.method === 'OPTIONS') {
        res.status(200).end();
        return;
    }

    if (req.method !== 'POST') {
        return res.status(405).json({ error: 'Method Not Allowed' });
    }

    const {
        prompt,
        image,
        endImage,
        aspectRatio = '16:9',
        duration = 4,
        resolution = '720p',
        generateAudio = true,
        negativePrompt
    } = req.body;

    // ë””ë²„ê¹…: ë°›ì€ ë°ì´í„° ë¡œê¹…
    console.log('[VideoGen] ========== REQUEST RECEIVED ==========');
    console.log('[VideoGen] Prompt:', prompt?.substring(0, 50));
    console.log('[VideoGen] Image exists:', !!image);
    console.log('[VideoGen] Image type:', typeof image);
    console.log('[VideoGen] Image starts with:', image?.substring(0, 30));
    console.log('[VideoGen] Image length:', image?.length);

    // ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ ì—†ì´ë„ ê°€ëŠ¥ (image-to-video ëª¨ë“œ)
    if (!prompt && !image) {
        return res.status(400).json({ error: 'Prompt or image is required' });
    }

    // ë¹ˆ í”„ë¡¬í”„íŠ¸ì¼ ë•Œ ê¸°ë³¸ê°’ ì„¤ì • (image-to-video ëª¨ë“œìš©)
    const finalPrompt = prompt || 'Bring this image to life with natural motion and cinematic quality';

    // Veo 3.1ì€ 16:9, 9:16ë§Œ ì§€ì› - ë‹¤ë¥¸ ë¹„ìœ¨ì€ 16:9ë¡œ ë³€í™˜
    const supportedRatios = ['16:9', '9:16'];
    const finalAspectRatio = supportedRatios.includes(aspectRatio) ? aspectRatio : '16:9';
    if (aspectRatio !== finalAspectRatio) {
        console.log(`[VideoGen] Unsupported aspect ratio ${aspectRatio} â†’ converted to ${finalAspectRatio}`);
    }

    // ëª¨ë“œ ê²°ì •: text-to-video, image-to-video, multi-image-to-video
    const mode = endImage ? 'multi-image' : (image ? 'image-to-video' : 'text-to-video');
    console.log('[VideoGen] Mode:', mode);

    const PROJECT_ID = process.env.GOOGLE_PROJECT_ID;
    if (!PROJECT_ID) {
        return res.status(500).json({
            error: 'Server misconfiguration',
            message: 'GOOGLE_PROJECT_ID not configured'
        });
    }

    const startTime = Date.now();

    try {
        console.log('[VideoGen] Starting Veo 3.1 video generation');
        console.log('[VideoGen] Mode:', mode);
        console.log('[VideoGen] Prompt:', finalPrompt.substring(0, 100));
        console.log('[VideoGen] Duration:', duration, 'seconds');
        console.log('[VideoGen] Resolution:', resolution);
        console.log('[VideoGen] Aspect Ratio:', aspectRatio);
        console.log('[VideoGen] Generate Audio:', generateAudio);

        // Authenticate with Google Cloud
        const credentialsJson = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON;
        if (!credentialsJson) {
            throw new Error('GOOGLE_APPLICATION_CREDENTIALS_JSON not configured');
        }
        const auth = new GoogleAuth({
            credentials: JSON.parse(credentialsJson),
            scopes: ['https://www.googleapis.com/auth/cloud-platform'],
        });
        const client = await auth.getClient();
        const tokenResponse = await client.getAccessToken();
        const accessToken = tokenResponse.token;

        // Helper: Extract base64 from data URL
        const extractBase64 = (dataUrl) => {
            if (!dataUrl) {
                console.error('[VideoGen] extractBase64: No data provided');
                return null;
            }

            // ë°˜ë“œì‹œ data URL í˜•ì‹ì´ì–´ì•¼ í•¨
            if (!dataUrl.startsWith('data:')) {
                console.error('[VideoGen] extractBase64: Invalid format - not a data URL');
                console.error('[VideoGen] extractBase64: Data starts with:', dataUrl.substring(0, 50));
                throw new Error('ì´ë¯¸ì§€ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
            }

            const matches = dataUrl.match(/^data:([^;]+);base64,(.+)$/);
            if (!matches) {
                console.error('[VideoGen] extractBase64: Failed to parse data URL');
                throw new Error('ì´ë¯¸ì§€ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨');
            }

            const mime = matches[1];
            const base64 = matches[2];
            console.log('[VideoGen] extractBase64: Success -', mime, 'length:', base64.length);
            return { base64, mime };
        };

        // Resolution is used directly (no restrictions)
        const finalResolution = resolution;

        // ì´ë¯¸ì§€ ë°ì´í„° ë¯¸ë¦¬ ì¶”ì¶œ (í”„ë¡¬í”„íŠ¸ ìµœì í™”ì— í•„ìš”)
        let startImgData = null;
        let endImgData = null;

        if (image) {
            startImgData = extractBase64(image);
        }
        if (endImage) {
            endImgData = extractBase64(endImage);
        }

        // Geminië¡œ í”„ë¡¬í”„íŠ¸ ìµœì í™” (ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ Veoì— ìµœì í™”ëœ ì˜ë¬¸ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜)
        console.log('[VideoGen] Optimizing prompt with Gemini...');
        const optimizedPrompt = await optimizePromptForVeo(
            finalPrompt,
            mode,
            accessToken,
            PROJECT_ID,
            startImgData,
            endImgData
        );
        console.log('[VideoGen] Optimized prompt:', optimizedPrompt.substring(0, 100));

        // ëª¨ë¸ ì„ íƒ (quality íŒŒë¼ë¯¸í„°ë¡œ ì œì–´, ê¸°ë³¸ê°’: fast)
        const qualityMode = req.body.quality || 'fast'; // 'fast' | 'standard'
        const MODEL_ID = qualityMode === 'standard'
            ? 'veo-3.1-generate-preview'  // í‘œì¤€ í’ˆì§ˆ (ë” ëŠë¦¬ì§€ë§Œ ê³ í’ˆì§ˆ)
            : 'veo-3.1-fast-generate-preview'; // ë¹ ë¥¸ ìƒì„±
        const endpoint = `https://us-central1-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/us-central1/publishers/google/models/${MODEL_ID}:predictLongRunning`;

        // ê³µì‹ ë¬¸ì„œ ê¸°ë°˜ ìš”ì²­ êµ¬ì¡° (ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        const requestBody = {
            instances: [
                {
                    prompt: optimizedPrompt
                }
            ],
            parameters: {
                aspectRatio: finalAspectRatio,
                sampleCount: 1,
                personGeneration: 'allow_adult' // ì„±ì¸ ì‚¬ëŒ ìƒì„± í—ˆìš©
            }
        };

        // ëª¨ë“œë³„ ì´ë¯¸ì§€ ì¶”ê°€ (ì´ë¯¸ ì¶”ì¶œí•œ ë°ì´í„° ì‚¬ìš©)
        if (mode === 'image-to-video' && startImgData) {
            requestBody.instances[0].image = {
                bytesBase64Encoded: startImgData.base64,
                mimeType: startImgData.mime
            };
        } else if (mode === 'multi-image' && startImgData && endImgData) {
            // ì‹œì‘ + ë ì´ë¯¸ì§€ (ì²« í”„ë ˆì„, ë§ˆì§€ë§‰ í”„ë ˆì„)
            requestBody.instances[0].image = {
                bytesBase64Encoded: startImgData.base64,
                mimeType: startImgData.mime
            };
            // Veo 3.1 last frame interpolation (ì˜¬ë°”ë¥¸ íŒŒë¼ë¯¸í„°ëª…: lastFrame)
            requestBody.instances[0].lastFrame = {
                bytesBase64Encoded: endImgData.base64,
                mimeType: endImgData.mime
            };
        }
        // text-to-video: ì´ë¯¸ì§€ ì—†ìŒ

        // Veo 3.x ì „ìš© íŒŒë¼ë¯¸í„°
        if (MODEL_ID.includes('veo-3')) {
            requestBody.parameters.durationSeconds = parseInt(duration);
            requestBody.parameters.resolution = finalResolution;
            requestBody.parameters.generateAudio = generateAudio;
        }

        // Add negative prompt if provided
        if (negativePrompt) {
            requestBody.parameters.negativePrompt = negativePrompt;
        }

        console.log('[VideoGen] Sending request to Veo 3.1...');
        console.log('[VideoGen] Endpoint:', endpoint);
        console.log('[VideoGen] Request body:', JSON.stringify(requestBody, null, 2).substring(0, 500));

        // Start video generation (long-running operation)
        const createResponse = await fetch(endpoint, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${accessToken}`,
                'Content-Type': 'application/json',
            },
            body: JSON.stringify(requestBody)
        });

        const createResponseText = await createResponse.text();
        console.log('[VideoGen] Create response status:', createResponse.status);
        console.log('[VideoGen] Create response:', createResponseText.substring(0, 500));

        if (!createResponse.ok) {
            let errMsg = 'Veo API error';
            try {
                const errData = JSON.parse(createResponseText);
                errMsg = errData.error?.message || errData.error?.status || createResponseText;
            } catch (e) {
                errMsg = createResponseText;
            }
            throw new Error(errMsg);
        }

        const operation = JSON.parse(createResponseText);
        const operationName = operation.name;
        console.log('[VideoGen] Operation started:', operationName);

        // ê³µì‹ ë¬¸ì„œ: fetchPredictOperationìœ¼ë¡œ í´ë§
        const fetchEndpoint = `https://us-central1-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/us-central1/publishers/google/models/${MODEL_ID}:fetchPredictOperation`;

        // Poll for completion (max 4 minutes)
        const maxWait = 240000;
        const pollInterval = 5000;
        let waited = 0;
        let result = null;

        while (waited < maxWait) {
            await new Promise(resolve => setTimeout(resolve, pollInterval));
            waited += pollInterval;

            const pollResponse = await fetch(fetchEndpoint, {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${accessToken}`,
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ operationName: operationName })
            });

            const pollText = await pollResponse.text();
            console.log(`[VideoGen] Poll status (${waited / 1000}s):`, pollText.substring(0, 200));

            let pollData;
            try {
                pollData = JSON.parse(pollText);
            } catch (e) {
                console.error('[VideoGen] Poll parse error:', pollText);
                continue;
            }

            if (pollData.done) {
                if (pollData.error) {
                    throw new Error(pollData.error.message || 'Video generation failed');
                }
                result = pollData;
                break;
            }
        }

        if (!result) {
            throw new Error('Video generation timeout - please try again');
        }

        // ì „ì²´ ì‘ë‹µ êµ¬ì¡° ë¡œê¹…
        console.log('[VideoGen] Full result:', JSON.stringify(result, null, 2).substring(0, 3000));

        // RAI í•„í„° ì²´í¬
        const raiFilteredCount = result.response?.raiMediaFilteredCount || 0;
        if (raiFilteredCount > 0) {
            console.log('[VideoGen] RAI filtered count:', raiFilteredCount);
            throw new Error(`ì½˜í…ì¸  ì •ì±…ìœ¼ë¡œ ${raiFilteredCount}ê°œ ì˜ìƒì´ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”.`);
        }

        // ê³µì‹ ë¬¸ì„œ ê¸°ì¤€: result.response.videos
        const videos = result.response?.videos || [];
        console.log('[VideoGen] Videos array length:', videos.length);

        if (videos.length === 0) {
            // ë‹¤ë¥¸ êµ¬ì¡° ì‹œë„
            const altVideos = result.videos || result.predictions || result.response?.predictions || [];
            console.log('[VideoGen] Alt videos length:', altVideos.length);
            if (altVideos.length === 0) {
                throw new Error('ì˜ìƒì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”.');
            }
            videos.push(...altVideos);
        }

        const video = videos[0];
        console.log('[VideoGen] First video object:', JSON.stringify(video).substring(0, 500));

        let videoData = null;

        if (video.bytesBase64Encoded) {
            // Base64ë¡œ ì§ì ‘ ë°˜í™˜ëœ ê²½ìš°
            const mimeType = video.mimeType || 'video/mp4';
            videoData = `data:${mimeType};base64,${video.bytesBase64Encoded}`;
            console.log('[VideoGen] Got base64 video');
        } else if (video.gcsUri) {
            // GCS URIì¸ ê²½ìš° - ë‹¤ìš´ë¡œë“œ ì‹œë„
            console.log('[VideoGen] Got GCS URI:', video.gcsUri);

            // GCSì—ì„œ ë‹¤ìš´ë¡œë“œ (ì„œë¹„ìŠ¤ ê³„ì • ê¶Œí•œ í•„ìš”)
            try {
                const gcsResponse = await fetch(video.gcsUri.replace('gs://', 'https://storage.googleapis.com/'), {
                    headers: {
                        'Authorization': `Bearer ${accessToken}`
                    }
                });

                if (gcsResponse.ok) {
                    const buffer = await gcsResponse.arrayBuffer();
                    const base64 = Buffer.from(buffer).toString('base64');
                    videoData = `data:video/mp4;base64,${base64}`;
                    console.log('[VideoGen] Downloaded from GCS successfully');
                } else {
                    // ê³µê°œ URLë¡œ ë°˜í™˜
                    videoData = video.gcsUri.replace('gs://', 'https://storage.googleapis.com/');
                    console.log('[VideoGen] Returning public GCS URL');
                }
            } catch (gcsErr) {
                console.error('[VideoGen] GCS download error:', gcsErr);
                videoData = video.gcsUri.replace('gs://', 'https://storage.googleapis.com/');
            }
        } else if (video.uri) {
            videoData = video.uri;
            console.log('[VideoGen] Got direct URI');
        }

        if (!videoData) {
            console.error('[VideoGen] Could not extract video data');
            throw new Error('ì˜ìƒ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        }

        const totalTime = Date.now() - startTime;
        console.log(`[VideoGen] Completed in ${totalTime}ms`);

        // ========== Supabaseì— ì§ì ‘ ì €ì¥ (413 ì—ëŸ¬ ë°©ì§€) ==========
        let savedVideo = null;
        let finalVideoUrl = videoData;

        // base64 ë°ì´í„°ì¸ ê²½ìš°ì—ë§Œ Supabaseì— ì €ì¥
        if (videoData.startsWith('data:video/')) {
            try {
                const supabase = createClient(
                    process.env.SUPABASE_URL,
                    process.env.SUPABASE_ANON_KEY
                );

                // Base64 â†’ Buffer
                const base64Data = videoData.replace(/^data:video\/\w+;base64,/, '');
                const buffer = Buffer.from(base64Data, 'base64');
                const fileName = `${Date.now()}-${Math.random().toString(36).substring(7)}.mp4`;

                console.log(`[VideoGen] Uploading to Supabase Storage... (${Math.round(buffer.length / 1024 / 1024 * 100) / 100}MB)`);

                // Storageì— ì—…ë¡œë“œ
                const { data: uploadData, error: uploadError } = await supabase.storage
                    .from('generated-videos')
                    .upload(fileName, buffer, {
                        contentType: 'video/mp4',
                        cacheControl: '3600'
                    });

                if (uploadError) {
                    console.error('[VideoGen] Storage upload error:', uploadError);
                    // ì—…ë¡œë“œ ì‹¤íŒ¨í•´ë„ base64ë¡œ ë°˜í™˜
                } else {
                    // Public URL ê°€ì ¸ì˜¤ê¸°
                    const { data: { publicUrl } } = supabase.storage
                        .from('generated-videos')
                        .getPublicUrl(fileName);

                    finalVideoUrl = publicUrl;
                    console.log('[VideoGen] Uploaded to Supabase:', publicUrl);

                    // DBì— ë©”íƒ€ë°ì´í„° ì €ì¥ (videos í…Œì´ë¸”ì´ ìˆë‹¤ë©´)
                    try {
                        const { data: dbData, error: dbError } = await supabase
                            .from('videos')
                            .insert({
                                video_url: publicUrl,
                                prompt: prompt,
                                model: MODEL_ID,
                                duration: duration,
                                resolution: finalResolution,
                                aspect_ratio: finalAspectRatio,
                                has_audio: generateAudio,
                                mode: mode
                            })
                            .select()
                            .single();

                        if (!dbError && dbData) {
                            savedVideo = dbData;
                            console.log('[VideoGen] Saved to DB:', savedVideo.id);
                        }
                    } catch (dbErr) {
                        console.log('[VideoGen] DB save skipped (table may not exist)');
                    }
                }
            } catch (supabaseErr) {
                console.error('[VideoGen] Supabase error:', supabaseErr);
                // Supabase ì‹¤íŒ¨í•´ë„ base64ë¡œ ë°˜í™˜
            }
        }

        return res.status(200).json({
            success: true,
            video: finalVideoUrl,
            savedVideo: savedVideo,
            debug: {
                processingTime: totalTime,
                model: MODEL_ID,
                duration: duration,
                resolution: finalResolution,
                aspectRatio: finalAspectRatio,
                hasAudio: generateAudio,
                originalPrompt: prompt,
                optimizedPrompt: optimizedPrompt
            }
        });

    } catch (err) {
        console.error('[VideoGen Error]', err);

        // ì—ëŸ¬ ë¡œê¹… - ì˜ì–´ + í•œêµ­ì–´ í‚¤ì›Œë“œ ëª¨ë‘ ì²´í¬
        const errMsgLower = err.message?.toLowerCase() || '';
        const errMsg = err.message || '';
        const errorType = (errMsgLower.includes('usage guidelines') || errMsgLower.includes('violate'))
            ? 'SAFETY_VIOLATION'
            : errMsgLower.includes('timeout')
                ? 'TIMEOUT'
                : (errMsgLower.includes('rai') || errMsgLower.includes('filter') ||
                   errMsg.includes('í•„í„°ë§') || errMsg.includes('ì½˜í…ì¸  ì •ì±…'))
                    ? 'CONTENT_FILTERED'
                    : 'GENERAL_ERROR';

        await logError(
            errorType,
            err.message,
            { prompt, aspectRatio, duration, resolution, generateAudio },
            { stack: err.stack }
        );

        // ì½˜í…ì¸  í•„í„°ë§ ì—ëŸ¬ëŠ” ë°”ë¡œ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ì „ë‹¬ (Gemini Flash ìŠ¤í‚µ)
        if (errorType === 'CONTENT_FILTERED') {
            console.log('[VideoGen] Content filtered - returning direct message');
            return res.status(400).json({
                error: 'Content filtered',
                message: err.message,
                friendlyMessage: {
                    message: "ì½˜í…ì¸  ì •ì±…ìœ¼ë¡œ ì¸í•´ ì˜ìƒì´ í•„í„°ë§ë˜ì—ˆì–´ìš” ğŸš«",
                    suggestion: "ë‹¤ë¥¸ ì´ë¯¸ì§€ë‚˜ í”„ë¡¬í”„íŠ¸ë¡œ ì‹œë„í•´ë³´ì„¸ìš”",
                    detail: "ğŸ’¡ Google VeoëŠ” ìƒì—… ê´‘ê³ , ë¸Œëœë“œ ë¡œê³ , ì œí’ˆ ëª©ì—… ë“±ì˜ ì½˜í…ì¸ ë¥¼ ì˜ìƒìœ¼ë¡œ ë§Œë“œëŠ” ê²ƒì„ ì œí•œí•  ìˆ˜ ìˆì–´ìš”. ì¼ë°˜ í’ê²½ì´ë‚˜ ì¶”ìƒì ì¸ ì´ë¯¸ì§€ë¡œ ì‹œë„í•´ë³´ì„¸ìš”."
                }
            });
        }

        // ë‹¤ë¥¸ ì—ëŸ¬ëŠ” Gemini Flashë¡œ ì¹œê·¼í•œ ë©”ì‹œì§€ ìƒì„±
        let friendlyMessage = null;
        try {
            const credentialsJson = process.env.GOOGLE_APPLICATION_CREDENTIALS_JSON;
            if (credentialsJson && PROJECT_ID) {
                const auth = new GoogleAuth({
                    credentials: JSON.parse(credentialsJson),
                    scopes: ['https://www.googleapis.com/auth/cloud-platform'],
                });
                const client = await auth.getClient();
                const tokenResponse = await client.getAccessToken();

                friendlyMessage = await generateFriendlyMessage({
                    errorType,
                    errorMessage: err.message,
                    prompt
                }, tokenResponse.token, PROJECT_ID);
            }
        } catch (flashErr) {
            console.log('[Flash Communicator] Failed to generate friendly message:', flashErr.message);
            friendlyMessage = getDefaultMessage({ errorMessage: err.message });
        }

        return res.status(500).json({
            error: 'Video generation failed',
            message: err.message,
            friendlyMessage
        });
    }
}
