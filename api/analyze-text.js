/**
 * Vercel Serverless Function - Text Analysis for Mockup Images
 *
 * ëª©ì—… ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ ë¶„ì„:
 * - Gemini Visionìœ¼ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€
 * - ê° í…ìŠ¤íŠ¸ì˜ í’ˆì§ˆ(ê°€ë…ì„±) í‰ê°€
 * - ê¹¨ì§„ í…ìŠ¤íŠ¸ ì˜ì—­ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë°˜í™˜
 */

const { createClient } = require('@supabase/supabase-js');

// ì—ëŸ¬ ë¡œê¹…
async function logError(errorType, errorMessage, requestData, responseData = null) {
    try {
        const supabaseUrl = process.env.SUPABASE_URL;
        const supabaseKey = process.env.SUPABASE_ANON_KEY;
        if (!supabaseUrl || !supabaseKey) return;

        const supabase = createClient(supabaseUrl, supabaseKey);
        await supabase.from('error_logs').insert({
            service: 'analyze-text',
            error_type: errorType,
            error_message: errorMessage,
            request_data: requestData,
            response_data: responseData,
            resolved: false
        });
    } catch (e) {
        console.error('[ErrorLog] Exception:', e.message);
    }
}

module.exports.config = {
    maxDuration: 30,
};

module.exports = async (req, res) => {
    // CORS
    res.setHeader('Access-Control-Allow-Credentials', true);
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'GET,OPTIONS,PATCH,DELETE,POST,PUT');
    res.setHeader('Access-Control-Allow-Headers', 'X-CSRF-Token, X-Requested-With, Accept, Accept-Version, Content-Length, Content-MD5, Content-Type, Date, X-Api-Version');

    if (req.method === 'OPTIONS') return res.status(200).end();
    if (req.method !== 'POST') return res.status(405).json({ error: 'Method Not Allowed' });

    const { image, originalText } = req.body;

    if (!image) {
        return res.status(400).json({ error: 'Image is required' });
    }

    const startTime = Date.now();

    try {
        const geminiApiKey = process.env.GEMINI_API_KEY;

        if (!geminiApiKey) {
            throw new Error('GEMINI_API_KEY not configured');
        }

        // ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
        let imageBase64 = image;
        let imageMimeType = 'image/png';

        if (image.startsWith('data:')) {
            const matches = image.match(/^data:([^;]+);base64,(.+)$/);
            if (matches) {
                imageMimeType = matches[1];
                imageBase64 = matches[2];
            }
        }

        // Gemini Vision APIë¡œ í…ìŠ¤íŠ¸ ë¶„ì„
        const geminiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${geminiApiKey}`;

        // AI ìƒì„± ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„ í”„ë¡¬í”„íŠ¸
        // í•µì‹¬: ë§¥ë½ ê¸°ë°˜ íŒë‹¨ - "ì´ ì¥ë©´ì—ì„œ ì´ ìœ„ì¹˜ì— ë§ëŠ” í…ìŠ¤íŠ¸ì¸ê°€?"
        const analysisPrompt = `You are analyzing an AI-generated image for TEXT QUALITY.

STEP 1: UNDERSTAND THE CONTEXT
First, identify what this image shows:
- Is it a subway station? A cafe? A billboard? A product mockup?
- What kind of text SHOULD appear in this context?

STEP 2: ANALYZE EACH TEXT AREA
For each text area:
1. What characters do you see?
2. Does it make sense IN THIS CONTEXT?
   - Subway station sign â†’ should be a real station name (ê°•ë‚¨, í™ëŒ€ì…êµ¬, etc.)
   - Cafe menu â†’ should be real drink/food names
   - Store sign â†’ should be a plausible business name
3. Is it gibberish or corrupted?
   - "ã„·ã„´ã…‡ã„¹" = gibberish consonants
   - "ì¹´ã…ë ˆ" = broken Korean
   - Random symbols = corrupted

STEP 3: SUGGEST CORRECTIONS
If text is broken/gibberish, suggest what it SHOULD say based on context.
- Subway sign with "ê°•ã„´ã…" â†’ suggest "ê°•ë‚¨"
- Cafe sign with "COfF33" â†’ suggest "COFFEE"

${originalText ? `HINT: The intended text was: "${originalText}"` : ''}

Return JSON:
{
  "imageContext": "brief description (e.g., 'subway station mockup', 'cafe interior')",
  "textAreas": [
    {
      "detectedText": "exactly what you see",
      "isValidText": true/false,
      "contextAppropriate": true/false,
      "suggestedText": "what it should say (if needs correction)",
      "quality": 1-10,
      "issues": [],
      "boundingBox": {"x": 0-100, "y": 0-100, "width": 0-100, "height": 0-100},
      "needsCorrection": true/false
    }
  ],
  "overallQuality": 1-10,
  "hasCorruptedText": true/false,
  "summary": "í•œê¸€ ìš”ì•½"
}

EXAMPLES:
1. Subway mockup with "ê°•ã„´ã…ì—­" â†’ needsCorrection: true, suggestedText: "ê°•ë‚¨ì—­"
2. Cafe with "ì•„ë©”ë¦¬ì¹´ë…¸" â†’ needsCorrection: false (valid text)
3. Billboard with "ã…ã„±ã…‚ã„·" â†’ needsCorrection: true, suggestedText: (infer from image context)
4. Store sign "OPEN" â†’ needsCorrection: false (valid English)

Be STRICT about gibberish. If it's not a real word, mark needsCorrection: true.`;

        console.log('[AnalyzeText] Starting analysis...');

        const response = await fetch(geminiUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{
                    parts: [
                        { text: analysisPrompt },
                        {
                            inline_data: {
                                mime_type: imageMimeType,
                                data: imageBase64
                            }
                        }
                    ]
                }],
                generationConfig: {
                    temperature: 0.1,
                    maxOutputTokens: 2048,
                    responseMimeType: 'application/json'
                }
            })
        });

        if (!response.ok) {
            const errText = await response.text();
            console.error(`[AnalyzeText] Gemini error (${response.status}):`, errText);
            throw new Error(`Gemini API failed: ${response.status}`);
        }

        const data = await response.json();
        let analysisResult = null;

        // ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for (const candidate of (data.candidates || [])) {
            for (const part of (candidate.content?.parts || [])) {
                if (part.text) {
                    try {
                        // JSON íŒŒì‹± ì‹œë„
                        analysisResult = JSON.parse(part.text);
                    } catch (e) {
                        // JSONì´ ì•„ë‹ˆë©´ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
                        console.log('[AnalyzeText] Response is not JSON, returning raw text');
                        analysisResult = { rawResponse: part.text };
                    }
                }
            }
        }

        if (!analysisResult) {
            throw new Error('No analysis result from Gemini');
        }

        const totalTime = Date.now() - startTime;
        console.log(`[AnalyzeText] Complete in ${totalTime}ms, hasCorrupted: ${analysisResult.hasCorruptedText}`);

        // ë³´ì •ì´ í•„ìš”í•œ ì˜ì—­ í•„í„°ë§
        const areasNeedingCorrection = analysisResult.textAreas?.filter(area => area.needsCorrection) || [];

        res.status(200).json({
            success: true,
            analysis: analysisResult,
            needsCorrection: areasNeedingCorrection.length > 0,
            correctionAreas: areasNeedingCorrection,
            debug: {
                totalTime: `${totalTime}ms`,
                textAreasFound: analysisResult.textAreas?.length || 0,
                areasNeedingCorrection: areasNeedingCorrection.length
            }
        });

    } catch (err) {
        console.error('[AnalyzeText Error]', err);

        await logError('ANALYSIS_ERROR', err.message, { hasImage: !!image }, { stack: err.stack });

        res.status(500).json({
            error: 'Text analysis failed',
            message: err.message,
            friendlyMessage: {
                message: 'í…ìŠ¤íŠ¸ ë¶„ì„ì— ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš” ğŸ”„',
                suggestion: 'ì´ë¯¸ì§€ í’ˆì§ˆì„ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ì‹œ ì—…ë¡œë“œí•´ë³´ì„¸ìš”.'
            }
        });
    }
};
